{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e674296",
   "metadata": {},
   "source": [
    "### 20184645 김영찬\n",
    "### 웹크롤링 후 데이터베이스 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed19ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링에 필요한 각 라이브러리, 모둘 임포트 및 설치\n",
    "#!pip install selenium\n",
    "#!pip install bs4\n",
    "#!pip install flask\n",
    "import re # 정규표현식을 위한 임포트\n",
    "import time # 웹 페이지가 뜨는 동안 시간지연을 하기 위해 임포트\n",
    "import urllib\n",
    "import sqlite3\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from flask import Flask,render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6849555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저, 크롬을 켜 알바몬 사이트에 접속\n",
    "browser = webdriver.Chrome(\"./chromedriver.exe\")\n",
    "browser.get(\"https://www.albamon.com/main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b167ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨 처음 홈페이지에 들어가고 기업/개인 을 선택하는 팝업에서 개인을 클릭\n",
    "main=browser.find_element_by_id(\"btn_MType\")\n",
    "main.click()\n",
    "\n",
    "# 크롤링 할 위치인 내가 사는 지역인 경기 - 수원시 장안구 - 장안구 전체 를 선택 후 검색\n",
    "browser.find_element_by_link_text(\"경기\").click()\n",
    "browser.find_element_by_link_text(\"수원시 장안구\").click()\n",
    "time.sleep(1)\n",
    "browser.find_element_by_id(\"dev_area_dong_code_B190\").click()\n",
    "s_location=browser.find_element_by_class_name(\"sch\")\n",
    "s_location.click()\n",
    "time.sleep(1) # 위치가 바뀌고 브라우저가 새로고침 되는동안 다음 동작이 실행되면 오류가 나기떄문에 1초의 시간지연을 두었음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a1596e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table alba_data already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25568/1504570758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# alba_data 테이블 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m cursor.execute('''\n\u001b[0m\u001b[0;32m      8\u001b[0m               \u001b[0mcreate\u001b[0m \u001b[0mtable\u001b[0m \u001b[0malba_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marea\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubject\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoney\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecently\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m ''') \n",
      "\u001b[1;31mOperationalError\u001b[0m: table alba_data already exists"
     ]
    }
   ],
   "source": [
    "# alba 데이터베이스 연결\n",
    "conn = sqlite3.connect('alba.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# alba_data 테이블 생성\n",
    "cursor.execute('''\n",
    "              create table alba_data(area text, subject text, money text, time text, recently text);\n",
    "''') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본격적으로 필요한 자료들을 불러오기 위해 뷰티풀 숩 객체 생성\n",
    "# current_url은 내가 직접 페에지를 들어간것이 아니고 위의 코드에서 자동으로 페이지에 들어갔기 떄문에\n",
    "# 현재 탭의 url을 가져와 준다.\n",
    "\n",
    "base_url = urllib.request.urlopen(browser.current_url).read()\n",
    "soup = BeautifulSoup(base_url,\"html.parser\")\n",
    "\n",
    "ths = []  # 테이블의 헤드를 담기 위한 리스트\n",
    "tds = []\n",
    "alba_data = [] # 알바의 정보들을 담기위함.\n",
    "\n",
    "# 크롤링해온 정보들의 필요없는문자들(ex.\\n, \\r, \\t)\n",
    "def clean_text(data):\n",
    "    data1 = re.sub('\\n|\\r|\\t|  ','',str(data))\n",
    "    data2 = re.sub('\\r\\n','',data1)\n",
    "    return data2\n",
    "\n",
    "\n",
    "# 지역 선택후 나온 페이지의 하단의 알바 정보들이 모영있는 테이블을 find\n",
    "wrap = soup.find('div',{\"class\":\"gListWrap\"}) \n",
    "table = wrap.find('table')\n",
    "t_head = table.find('thead').find_all('th') # 찾은 테이블의 헤드(카테고리?(지역/금여금액/직업명 등등..))\n",
    "t_body = table.find('tbody') # 찾은 테이블의 바디(알바들의 직접적인 정보)\n",
    "\n",
    "# 테이블의 헤드를 하니싹 ths리스트에 담는다.\n",
    "for th in t_head:\n",
    "    ths.append(th.get_text())\n",
    "\n",
    "# 알바 정보들의 직접적인 정보들을 수집\n",
    "for tr in t_body.find_all('tr'):\n",
    "    area = tr.find('td',{'class':'area'}).find('div') # 알바를 하는 지역의 정보를 담고 있는 div태그\n",
    "    area.span.decompose() # 이 div 태그에는 span태그안에 다른 텍스트가 있는데 이 택스트를 제외한 값만 가져오기 위하여 사용\n",
    "    subject_name = tr.find('td',{'class':'subject'}).find('p',{'class':'cName'}).text # p태그 안의 cName(기업명)을 수집\n",
    "    subject_ctit = tr.find('td',{'class':'subject'}).find('p',{'class':'cTit'}).text # p태그 안의 cTit(모집 제목)을 수집\n",
    "    pay_money = tr.find('td',{'class':'pay'}).find('p',{'class':'money'}).find(\"img\")[\"alt\"] \n",
    "    #일급 / 시급 / 월급과 같은 급여 지급방식이 나뉘어져 있는데 이 부분은 img 태그안의 alt속성에 표기되어있어 리스트의 [\"alt\"]의 택스트만 수집\n",
    "    pay_won = tr.find('td',{'class':'pay'}).find('p',{'class':'won'}).text # p태그 안의 won(급여)을 수집\n",
    "    # for문을 한개만 사용하여 접근하려 했지만 급여 시간의 td태그에는 class 이름이 없었기 떄문에 결국 for문을 한개 더사용하여\n",
    "    # 3번째 위치에 있는 급여 시간 수집\n",
    "    tds = list(tr.find_all('td'))\n",
    "    for td in tds:\n",
    "        time = tds[3].text\n",
    "    # 등록일 정보 수집\n",
    "    recently = tr.find('td',{'class':'recently'}).text\n",
    "    # 위에서 수집한 알바정보들을 불필요한 문자들을 제거한 후 alba_data 리스트에 담는다.\n",
    "    alba_data.append([clean_text(area.text),clean_text(subject_name)+clean_text(subject_ctit),clean_text(pay_money)+clean_text(pay_won),clean_text(time),clean_text(recently)])\n",
    "    \n",
    "    cursor.execute('''\n",
    "    insert into alba_data(area, subject, money, time, recently) values (?,?,?,?,?)''',\n",
    "                  (clean_text(area.text), clean_text(subject_name)+clean_text(subject_ctit), clean_text(pay_money)+clean_text(pay_won),\n",
    "                  clean_text(time),clean_text(recently)))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d677b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area : 장안구 조원동, subject: 쿠팡풀필먼트서비스 [여주쿠팡]#품질관리&검수센터#쉬운업무#월최대270만, money : 월급2,705,195원, time : 19:00~04:00, recently : 34분전\n",
      "\n",
      "\n",
      "area : 장안구 조원동, subject: [쿠팡/선착순]박스분류(단순) #하루14만6천원(식사제공), money : 일급146,375원, time : 21:00~06:00, recently : 34분전\n",
      "\n",
      "\n",
      "area : 장안구 조원동, subject: #초보가능 #동반근무 #하루알바 주급65만가능/원하는요일/셔틀제공/단기/쿠팡/용인, money : 일급96,750원, time : 시간협의, recently : 34분전\n",
      "\n",
      "\n",
      "area : 장안구 조원동, subject: #CFS #쾌적한환경 #무료셔틀 #초보환영 #동 [쿠팡]안성5,6,7 #입사축하금100만원 #HUB #선착순, money : 월급2,845,000원, time : 09:00~18:00, recently : 35분전\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터베이스에서 area 속성이 ~조원동으로 끝나는 행만 검색\n",
    "cursor.execute('select * from alba_data where area like \"%조원동\"')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:    \n",
    "    print(\"area : %s, subject: %s, money : %s, time : %s, recently : %s\" % \n",
    "          (row[0],row[1],row[2],row[3],row[4]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df87e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
